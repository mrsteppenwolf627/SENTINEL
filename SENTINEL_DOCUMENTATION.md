# üõ°Ô∏è Sentinel ‚Äî Documentaci√≥n T√©cnica

**Versi√≥n:** 2.0-dev (Phase 2b ‚Äî LLM Brain)
**Fecha:** 27 de Febrero, 2026

---

## üìñ Introducci√≥n y Visi√≥n

**Sentinel** es un sistema de agente aut√≥nomo dise√±ado para la gesti√≥n y auto-remediaci√≥n de incidentes de infraestructura. Su objetivo es recibir alertas, enriquecer el contexto con historial de la base de datos, diagnosticar causas ra√≠z usando un LLM, evaluar riesgos y ejecutar acciones correctivas autom√°ticamente o solicitar aprobaci√≥n humana cuando sea necesario.

**Visi√≥n a Futuro:**
Este proyecto es la semilla de un **SaaS de Observabilidad y Remediaci√≥n Aut√≥noma** a escala global. El objetivo final es integrar LLMs avanzados para diagn√≥sticos complejos y conectores reales con nubes (AWS, Azure, GCP), Kubernetes y sistemas legacy.

---

## üèóÔ∏è Arquitectura y Estructura del Proyecto

El sistema sigue una **Arquitectura Hexagonal** para garantizar que cada componente sea reemplazable sin afectar al resto. La regla central: el n√∫cleo (`app/core`) nunca importa la infraestructura (`app/infrastructure`).

### √Årbol de Directorios
```text
Sentinel/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                      # üöÄ Punto de entrada (API FastAPI y Loop de control)
‚îÇ   ‚îú‚îÄ‚îÄ core/                        # üß† Cerebro y Contratos ‚Äî sin dependencias externas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities.py              # Alert, Incident, Diagnosis, RemediationPlan,
‚îÇ   ‚îÇ   ‚îÇ                            #   EnrichedContext, AuditLog
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ interfaces.py            # ABCs: IIngestionModule, IAnalysisModule(EnrichedContext), etc.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Pydantic V2 Settings (incl. ANTHROPIC_API_KEY, LLM_MODEL)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ logging.py               # Logger estructurado JSON
‚îÇ   ‚îú‚îÄ‚îÄ modules/                     # üß© Adaptadores de aplicaci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingestion/               # AlertSimulator ‚Äî genera alertas simuladas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ engine.py            # RuleBasedAnalyzer ‚Äî motor de reglas (fallback)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rules.py             # COMMON_RULES ‚Äî 4 reglas deterministas
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ llm_analyzer.py      # LLMAnalyzer ‚Äî Claude via LangChain (primario)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ context/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ builder.py           # ContextBuilderService ‚Äî enriquece Alert con historial DB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ policy/                  # RiskEvaluator ‚Äî matriz Safe/Moderate/Critical
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ action/                  # ActionExecutor ‚Äî ejecuci√≥n mockeada
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ audit/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ service.py           # AuditService ‚Äî persistencia JSONL en audit.log
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ db_service.py        # PostgresAuditService ‚Äî IAuditModule para PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ infrastructure/              # üóÑÔ∏è Capa de infraestructura ‚Äî solo conoce SQLAlchemy
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ models.py            # ORM: IncidentModel, RemediationPlanModel, AuditLogModel
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ repositories.py      # Domain-pure repos + get_recent_similar,
‚îÇ   ‚îÇ                                #   get_past_executed_for_source
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îî‚îÄ‚îÄ unit/
‚îÇ           ‚îú‚îÄ‚îÄ test_analysis.py     # Tests RuleBasedAnalyzer (usa EnrichedContext)
‚îÇ           ‚îú‚îÄ‚îÄ test_audit.py        # Tests AuditService JSONL
‚îÇ           ‚îî‚îÄ‚îÄ test_llm_analyzer.py # Tests fallback de LLMAnalyzer (sin API real)
‚îú‚îÄ‚îÄ alembic/                         # Migraciones de base de datos (async)
‚îÇ   ‚îú‚îÄ‚îÄ env.py                       # Configurado con Base.metadata de models.py
‚îÇ   ‚îî‚îÄ‚îÄ versions/
‚îÇ       ‚îî‚îÄ‚îÄ a39f60d0d637_*.py        # Migraci√≥n inicial: incidents, remediation_plans, audit_logs
‚îú‚îÄ‚îÄ alembic.ini                      # URL: postgresql+asyncpg://postgres:postgrespassword@localhost:5432/sentinel
‚îú‚îÄ‚îÄ docker-compose.yml               # PostgreSQL 15-alpine con healthcheck
‚îú‚îÄ‚îÄ pytest.ini                       # asyncio_mode=strict, filtro UserWarning Python 3.14
‚îú‚îÄ‚îÄ .env                             # ANTHROPIC_API_KEY, LLM_MODEL (no versionado)
‚îú‚îÄ‚îÄ requirements.txt                 # 17 dependencias Python
‚îú‚îÄ‚îÄ PROJECT_CONTEXT.md               # Memoria central del proyecto
‚îú‚îÄ‚îÄ SENTINEL_DOCUMENTATION.md       # üìÑ Este documento
‚îî‚îÄ‚îÄ README.md                        # Gu√≠a de inicio r√°pido
```

### Flujo de Datos (Pipeline v2.0-dev ‚Äî Phase 2b)

```
AlertSimulator
      ‚îÇ  Alert
      ‚ñº
ContextBuilderService  ‚îÄ‚îÄ‚ñ∫ PostgreSQL (incidentes recientes + remediaciones pasadas)
      ‚îÇ  EnrichedContext
      ‚ñº
LLMAnalyzer (Claude)
      ‚îÇ  si error / sin API key
      ‚îî‚îÄ‚îÄ‚ñ∫ RuleBasedAnalyzer (fallback autom√°tico)
      ‚îÇ  Diagnosis
      ‚ñº
RiskEvaluator
      ‚îÇ  RemediationPlan
      ‚ñº
ActionExecutor ‚îÄ‚îÄ‚îÄ‚îÄ (si requires_approval=False)
      ‚îÇ  bool (success)
      ‚ñº
IAuditModule ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ AuditService (JSONL)  ‚Üê activo por defecto
                ‚îî‚îÄ‚îÄ  PostgresAuditService  ‚Üê disponible, activar via DI
```

---

## üîë Modelos de Dominio (`app/core/entities.py`)

### `Alert`
| Campo | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `id` | `str` (UUID) | Identificador √∫nico generado autom√°ticamente |
| `source` | `str` | Sistema de origen (ej. `"web-server-01"`) |
| `timestamp` | `datetime` | UTC-aware, generado con `datetime.now(timezone.utc)` |
| `severity` | `AlertSeverity` | `INFO \| WARNING \| CRITICAL \| FATAL` |
| `message` | `str` | Descripci√≥n del incidente |
| `metadata` | `dict` | Datos adicionales (ej. `{"cpu_usage": 95}`) |

### `Incident`
| Campo | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `id` | `str` (UUID) | Identificador √∫nico generado autom√°ticamente |
| `alert_id` | `str` | ID de la alerta que origin√≥ el incidente |
| `source` | `str` | Sistema de origen |
| `severity` | `AlertSeverity` | Severidad heredada de la alerta |
| `message` | `str` | Descripci√≥n del incidente |
| `metadata` | `dict` | Datos adicionales |
| `status` | `Literal` | `"OPEN" \| "ANALYZING" \| "MITIGATING" \| "CLOSED"` |
| `created_at` | `datetime` | UTC-aware, auto-generado |
| `closed_at` | `Optional[datetime]` | Momento de cierre, `None` mientras activo |

### `Diagnosis` *(actualizado en v2.0-dev Phase 2b)*
| Campo | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `alert_id` | `str` | ID de la alerta analizada |
| `root_cause` | `str` | Causa ra√≠z identificada |
| `confidence` | `float` | 0.0‚Äì1.0 (validado con `Field(ge=0.0, le=1.0)`) |
| `alternative_hypotheses` | `list[str]` | Hip√≥tesis alternativas evaluadas (LLM) |
| `reasoning_trace` | `str` | Cadena de razonamiento paso a paso (LLM); `""` para el rule engine |
| `suggested_actions` | `list[ActionType]` | Acciones sugeridas ordenadas por preferencia |

### `EnrichedContext` *(nuevo en v2.0-dev Phase 2b)*
| Campo | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `alert` | `Alert` | La alerta original que dispar√≥ el an√°lisis |
| `recent_similar_incidents` | `list[Incident]` | Incidentes recientes (24h) con mismo `source` o `severity` |
| `past_remediations_for_source` | `list[RemediationPlan]` | √öltimas 5 remediaciones ejecutadas para ese `source` |

### `RemediationPlan`
| Campo | Tipo | Descripci√≥n |
| :--- | :--- | :--- |
| `id` | `str` (UUID) | ID del plan |
| `diagnosis` | `Diagnosis` | Diagn√≥stico que origina el plan |
| `action_type` | `ActionType` | Acci√≥n a ejecutar |
| `risk_level` | `RiskLevel` | `SAFE \| MODERATE \| CRITICAL` |
| `requires_approval` | `bool` | Si requiere aprobaci√≥n humana |
| `status` | `Literal` | `"PENDING" \| "APPROVED" \| "EXECUTED" \| "FAILED"` |

---

## üß† LLM Brain (`app/modules/analysis/llm_analyzer.py`) *(nuevo en Phase 2b)*

### Principio de dise√±o
El `LLMAnalyzer` recibe un `EnrichedContext` (con historial de DB) y llama a Claude para producir un `Diagnosis` con cadena de razonamiento causal. No usa la librer√≠a `instructor` ‚Äî utiliza `ChatAnthropic.with_structured_output(_LLMDiagnosisOutput)` de LangChain para extracci√≥n Pydantic confiable via tool_use nativo de Anthropic.

### Esquema interno `_LLMDiagnosisOutput`
Modelo Pydantic interno que el LLM rellena (excluye `alert_id` para evitar que el LLM lo invente):
```python
class _LLMDiagnosisOutput(BaseModel):
    root_cause: str
    confidence: float          # Field(ge=0.0, le=1.0)
    alternative_hypotheses: List[str]
    reasoning_trace: str
    suggested_actions: List[ActionType]
```
Tras la llamada, se construye el `Diagnosis` final inyectando `alert_id=context.alert.id`.

### Fallback autom√°tico
```
LLMAnalyzer.analyze(context)
    ‚Üí intenta _call_llm(context)
    ‚Üí si cualquier excepci√≥n ‚Üí logger.warning + fallback.analyze(context)
```
La degradaci√≥n es transparente. El resto del pipeline no sabe si el resultado vino del LLM o del rule engine.

### Activaci√≥n
Crear `.env` en la ra√≠z del proyecto:
```env
ANTHROPIC_API_KEY=sk-ant-...
LLM_MODEL=claude-sonnet-4-6     # opcional, este es el default
```
Si `ANTHROPIC_API_KEY` est√° vac√≠o, `main.py` usa directamente `RuleBasedAnalyzer`.

---

## üåç ContextBuilderService (`app/modules/context/builder.py`) *(nuevo en Phase 2b)*

Antes de llamar al analizador, el orquestador pasa por `ContextBuilderService.build(alert)` que:

1. Consulta `IncidentRepository.get_recent_similar(source, severity, hours=24)` ‚Äî incidentes en las √∫ltimas 24h que compartan `source` o `severity`.
2. Consulta `PlanRepository.get_past_executed_for_source(source, limit=5)` ‚Äî las √∫ltimas 5 remediaciones ejecutadas para ese `source`.
3. Retorna `EnrichedContext(alert=alert, recent_similar_incidents=..., past_remediations_for_source=...)`.

**Degradaci√≥n elegante**: si PostgreSQL no est√° disponible, captura la excepci√≥n y retorna `EnrichedContext(alert=alert)` con listas vac√≠as. El LLM recibe menos contexto pero el pipeline no falla.

---

## üóÑÔ∏è Capa de Persistencia (`app/infrastructure/database/`)

### Principio de dise√±o
El n√∫cleo (`app/core`, `app/modules`) **nunca importa SQLAlchemy**. Los repositorios son los √∫nicos que conocen los modelos ORM.

### Modelos ORM (`models.py`)
| Tabla | Modelo ORM | Entidad de Dominio |
| :--- | :--- | :--- |
| `incidents` | `IncidentModel` | `Incident` |
| `remediation_plans` | `RemediationPlanModel` | `RemediationPlan` |
| `audit_logs` | `AuditLogModel` | `AuditLog` |

### Repositorios (`repositories.py`)
| Clase | M√©todo | Descripci√≥n |
| :--- | :--- | :--- |
| `IncidentRepository` | `save(incident)` | Persiste un `Incident` |
| `IncidentRepository` | `get_by_id(id)` | Recupera por ID |
| `IncidentRepository` | `get_recent_similar(source, severity, hours=24)` | Incidentes similares recientes |
| `PlanRepository` | `save(plan, incident_id)` | Persiste un `RemediationPlan` |
| `PlanRepository` | `get_past_executed_for_source(source, limit=5)` | Remediaciones pasadas ejecutadas |
| `AuditRepository` | `log_event(audit)` | Persiste un `AuditLog` |

### Servicios de Auditor√≠a (coexisten)
| Clase | Archivo | Backend | Cu√°ndo usar |
| :--- | :--- | :--- | :--- |
| `AuditService` | `modules/audit/service.py` | Archivo JSONL | Desarrollo local r√°pido, sin Docker |
| `PostgresAuditService` | `modules/audit/db_service.py` | PostgreSQL | Staging y producci√≥n, con Docker activo |

---

## ‚öôÔ∏è Configuraci√≥n (`app/core/config.py`)

| Setting | Default | Descripci√≥n |
| :--- | :--- | :--- |
| `ANTHROPIC_API_KEY` | `""` | API key de Claude. Si est√° vac√≠o, se usa el rule engine. |
| `LLM_MODEL` | `claude-sonnet-4-6` | Modelo de Claude usado por `LLMAnalyzer`. |
| `DATABASE_URL` | `postgresql+asyncpg://...` | URL async de PostgreSQL para repos y context builder. |
| `AUTO_APPROVE_MODERATE_ACTIONS` | `True` | Si True, acciones MODERATE se auto-ejecutan. |
| `AUDIT_FILE_PATH` | `audit.log` | Ruta del log JSONL. |
| `LOG_LEVEL` | `INFO` | Nivel de logging ra√≠z. |

---

## ‚öôÔ∏è Pol√≠tica de Riesgo (`app/modules/policy/risk_manager.py`)

| ActionType | RiskLevel | Auto-ejecuta |
| :--- | :--- | :--- |
| `NOTIFICATION` | SAFE | ‚úÖ Siempre |
| `CLEAR_CACHE` | SAFE | ‚úÖ Siempre |
| `SCALE_UP` | MODERATE | ‚öôÔ∏è Si `AUTO_APPROVE_MODERATE_ACTIONS=True` |
| `RESTART_SERVICE` | MODERATE | ‚öôÔ∏è Si `AUTO_APPROVE_MODERATE_ACTIONS=True` |
| `BLOCK_IP` | MODERATE | ‚öôÔ∏è Si `AUTO_APPROVE_MODERATE_ACTIONS=True` |
| `MANUAL_INTERVENTION` | CRITICAL | ‚ùå Nunca (siempre requiere aprobaci√≥n) |

---

## üõ†Ô∏è C√≥mo Funciona y Se Ejecuta

### Requisitos Previos
- Python 3.11+
- Docker Desktop (para PostgreSQL ‚Äî opcional)
- API key de Anthropic (para LLM Brain ‚Äî opcional)

### Instalaci√≥n
```bash
# Activar entorno virtual
./.venv/Scripts/Activate.ps1        # Windows
source .venv/bin/activate           # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt
```

### Configurar LLM Brain (opcional)
```bash
# Crear .env en la ra√≠z del proyecto
echo "ANTHROPIC_API_KEY=sk-ant-..." > .env
```

### Levantar la base de datos (opcional)
```bash
docker-compose up -d
alembic upgrade head
```

### Ejecuci√≥n del Agente
```bash
uvicorn app.main:app --reload
```
El endpoint `/` muestra qu√© analizador est√° activo (`LLMAnalyzer` o `RuleBasedAnalyzer`).

### Endpoints Disponibles
| Endpoint | M√©todo | Descripci√≥n |
| :--- | :--- | :--- |
| `/` | GET | Health check + analizador activo |
| `/docs` | GET | Swagger UI autom√°tico de FastAPI |
| `/audit` | GET | Visor HTML de los √∫ltimos 50 eventos de auditor√≠a |
| `/simulate` | POST | Inyecci√≥n manual de una alerta personalizada |

### Ejecutar Tests
```bash
pytest -v
```
**Estado actual:** 5/5 passing, 0 warnings.

---

## üõ£Ô∏è Roadmap y Estado del Proyecto

### ‚úÖ Fase 1: MVP 1.1 ‚Äî Foundation Hardened (Completado)
- [x] Estructura base, Git y logging estructurado JSON.
- [x] Simulador de alertas (CPU, Memoria, Disco, Latencia, DB).
- [x] Motor de reglas determinista con formateo seguro de metadata.
- [x] Pol√≠tica de riesgo Safe/Moderate/Critical con flag correctamente nombrado.
- [x] Ejecutor mockeado (simula reinicios, escalados, notificaciones).
- [x] Auditor√≠a JSONL as√≠ncrona.
- [x] Orquestaci√≥n as√≠ncrona en background con FastAPI lifespan.
- [x] Visor de auditor√≠a HTML con color-coding por severidad.
- [x] 5/5 tests pasando, cero warnings.

### ‚úÖ Fase 2a: Persistence Layer (Completado)
- [x] `app/infrastructure/database/` con SQLAlchemy 2.0, Alembic async, Docker Compose.
- [x] Entidad `Incident`: ciclo de vida OPEN ‚Üí ANALYZING ‚Üí MITIGATING ‚Üí CLOSED.
- [x] Repositorios domain-pure: mapeo entidad ‚Üî ORM interno, el n√∫cleo no conoce SQLAlchemy.
- [x] `PostgresAuditService`: IAuditModule adapter para PostgreSQL, coexiste con JSONL.

### ‚úÖ Fase 2b: LLM Brain (Completado)
- [x] **`LLMAnalyzer`**: Claude via `langchain-anthropic`, `with_structured_output`, fallback autom√°tico.
- [x] **`ContextBuilderService`**: enriquece Alert con historial de DB antes del an√°lisis.
- [x] **`EnrichedContext`**: nueva entidad de dominio con alert + historial.
- [x] **`Diagnosis` evolucionado**: `alternative_hypotheses`, `reasoning_trace`, validaci√≥n `ge/le`.
- [x] **`IAnalysisModule`** actualizado: `analyze(context: EnrichedContext)`.
- [x] **Repositorios extendidos**: `get_recent_similar`, `get_past_executed_for_source`.

### üîÑ Fase 2c: Orquestaci√≥n y Aprobaci√≥n (Pr√≥ximo)
- [ ] **LangGraph**: Refactorizar el loop de procesamiento en un agente LangGraph.
- [ ] **Webhook Ingestion**: Endpoint real para Prometheus/Grafana Alertmanager.
- [ ] **Human Approval API**: `POST /plans/{id}/approve` y `/plans/{id}/reject`.

### üåê Fase 3: Conectores Reales
- [ ] Integraci√≥n Slack/PagerDuty.
- [ ] Ejecutores reales (SSH via Paramiko, Kubernetes API, AWS SDK).
- [ ] Redis para streaming de eventos.
- [ ] Dashboard React.
- [ ] Multi-tenancy SaaS.

---

## üí° Gu√≠a para Desarrolladores y Agentes LLM

### A√±adir una nueva fuente de alertas
1. Crea una clase en `app/modules/ingestion/` que implemente `IIngestionModule`.
2. Exp√≥rtala desde `app/modules/ingestion/__init__.py`.
3. √ösala en `app/main.py` en lugar de (o junto a) `AlertSimulator`.

### A√±adir una nueva regla de detecci√≥n
A√±ade una entrada en `COMMON_RULES` en `app/modules/analysis/rules.py`:
```python
Rule(
    name="High Latency",
    condition=lambda a: "latency" in a.message.lower(),
    root_cause_template="Service latency exceeded threshold: {latency_ms}ms",
    suggested_actions=[ActionType.SCALE_UP, ActionType.NOTIFICATION]
)
```
Las claves de metadata que no existan se renderizar√°n como `"N/A"` de forma segura.

### Activar el LLM Brain
Crea `.env` con `ANTHROPIC_API_KEY`. El `main.py` detecta autom√°ticamente la clave y usa `LLMAnalyzer`. Sin clave, usa `RuleBasedAnalyzer`. El endpoint `/` muestra cu√°l est√° activo.

### Activar PostgreSQL como backend de auditor√≠a
En `app/main.py`, reemplaza la instancia de `AuditService` por `PostgresAuditService`:
```python
from app.modules.audit.db_service import PostgresAuditService
audit_service = PostgresAuditService(session=db_session)
```
El `PostgresAuditService` implementa `IAuditModule`, el resto del c√≥digo no cambia.

### Escribir tests para nuevos analizadores
Los tests deben pasar `EnrichedContext` (no `Alert` directamente):
```python
from app.core.entities import Alert, AlertSeverity, EnrichedContext

context = EnrichedContext(alert=Alert(
    source="server-01",
    severity=AlertSeverity.CRITICAL,
    message="High CPU usage",
    metadata={"cpu_usage": 99, "component": "cpu"}
))
diagnosis = await analyzer.analyze(context)
```

### Logging
Siempre usa `logger.info(msg, extra={...})` con diccionarios en `extra`. **No uses `message` como clave en `extra`** (clave reservada de Python logging ‚Äî usa `alert_message`).

---

*Documentaci√≥n mantenida por Claude Code ‚Äî Lead Implementation Engineer.*
