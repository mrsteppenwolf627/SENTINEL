# SENTINEL Phase 2: Persistence Layer Design

This document details the transition from the file-based MVP persistence layer to a robust PostgreSQL setup, following the existing hexagonal architecture.

## 1. SQLAlchemy Models
These models map directly to our domain entities but include relational concepts.

```python
import uuid
from datetime import datetime
from sqlalchemy import Column, String, Float, Boolean, DateTime, ForeignKey, Enum as SQLEnum
from sqlalchemy.orm import declarative_base, relationship
from sqlalchemy.dialects.postgresql import JSONB

from app.core.entities import AlertSeverity, RiskLevel, ActionType

Base = declarative_base()

class IncidentModel(Base):
    """
    Represents an ongoing or historical incident derived from an alert.
    """
    __tablename__ = "incidents"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    status = Column(String, default="OPEN", index=True) # E.g., OPEN, ANALYZING, MITIGATING, CLOSED
    source = Column(String, index=True)                 # Original alert source
    severity = Column(SQLEnum(AlertSeverity), nullable=False)
    message = Column(String, nullable=False)
    metadata_json = Column(JSONB, default=dict)         # Alert metadata
    enriched_context = Column(JSONB, default=dict)      # Context added by Context Gatherer
    rca_hypothesis = Column(String)                     # LLM Root Cause hypothesis
    created_at = Column(DateTime(timezone=True), default=datetime.utcnow, index=True)
    
    # Relationships
    plans = relationship("RemediationPlanModel", back_populates="incident", cascade="all, delete-orphan")

class RemediationPlanModel(Base):
    """
    Represents an actionable plan attached to an incident.
    """
    __tablename__ = "remediation_plans"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    incident_id = Column(String(36), ForeignKey("incidents.id", ondelete="CASCADE"), index=True, nullable=False)
    
    # Flattened Diagnosis info
    diagnosis_root_cause = Column(String, nullable=False)
    diagnosis_confidence = Column(Float, nullable=False)
    
    action_type = Column(SQLEnum(ActionType), nullable=False, index=True)
    risk_level = Column(SQLEnum(RiskLevel), nullable=False)
    requires_approval = Column(Boolean, default=False)
    status = Column(String, default="PENDING", index=True) # PENDING, APPROVED, EXECUTED, FAILED
    created_at = Column(DateTime(timezone=True), default=datetime.utcnow)
    
    # Relationships
    incident = relationship("IncidentModel", back_populates="plans")

class AuditLogModel(Base):
    """
    WORM (Write-Once-Read-Many) Audit log table.
    """
    __tablename__ = "audit_logs"

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    timestamp = Column(DateTime(timezone=True), default=datetime.utcnow, index=True)
    component = Column(String, nullable=False, index=True)
    event = Column(String, nullable=False, index=True)
    details = Column(JSONB, nullable=False)
```

## 2. Alembic Setup Instructions

Setup Alembic for async database migrations:

```bash
# 1. Install dependencies
pip install sqlalchemy alembic psycopg2-binary asyncpg

# 2. Initialize Alembic with async template
alembic init -t async alembic

```

**Configure `alembic.ini`** (around line 63):
```ini
sqlalchemy.url = postgresql+asyncpg://postgres:postgrespassword@localhost:5432/sentinel
```

**Configure `alembic/env.py`**:
Import your Base and configure the metadata near the top:
```python
import asyncio
from logging.config import fileConfig

from sqlalchemy import pool
from sqlalchemy.ext.asyncio import async_engine_from_config
from alembic import context

# Import target metadata from your models
from app.infrastructure.database.models import Base
target_metadata = Base.metadata

# ... REST OF AUTOGENERATED env.py ...
```

**Run First Migration**:
```bash
alembic revision --autogenerate -m "Initial schema: incidents, plans, audit"
alembic upgrade head
```

## 3. Repository Pattern

We ensure the rest of the app relies on PyDantic domain entities, completely ignorant of SQLAlchemy. 
These repositories map models back and forth.

```python
from typing import Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select

from app.infrastructure.database.models import IncidentModel, RemediationPlanModel, AuditLogModel
from app.core.entities import Incident, RemediationPlan, AuditLog # Assuming Incident entity is created

class IncidentRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
        
    async def save(self, incident: IncidentModel) -> IncidentModel:
        self.session.add(incident)
        await self.session.flush()
        return incident
        
    async def get_by_id(self, incident_id: str) -> Optional[IncidentModel]:
        result = await self.session.execute(
            select(IncidentModel).where(IncidentModel.id == incident_id)
        )
        return result.scalars().first()

class PlanRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
        
    async def save(self, plan: RemediationPlanModel) -> RemediationPlanModel:
        self.session.add(plan)
        await self.session.flush()
        return plan

class AuditRepository:
    def __init__(self, session: AsyncSession):
        self.session = session
        
    async def log_event(self, audit_entity: AuditLog) -> AuditLogModel:
        db_log = AuditLogModel(
            id=audit_entity.id,
            timestamp=audit_entity.timestamp,
            component=audit_entity.component,
            event=audit_entity.event,
            details=audit_entity.details
        )
        self.session.add(db_log)
        await self.session.flush()
        return db_log
```

## 4. Migrating the IAuditModule Interface

To adhere to the existing Hexagonal Architecture, the core app should never know about `AuditRepository` or SQLAlchemy. The `IAuditModule` acts as our primary port. We create a new Adapter (`PostgresAuditService`) that implements `IAuditModule`.

```python
# File: app/modules/audit/db_service.py

from sqlalchemy.ext.asyncio import AsyncSession
from app.core.interfaces import IAuditModule
from app.core.entities import AuditLog
from app.infrastructure.database.repositories import AuditRepository

class PostgresAuditService(IAuditModule):
    """
    Adapter implementing the core IAuditModule port.
    Delegates persistence logic to the underlying SQLAlchemy AuditRepository.
    """
    def __init__(self, session: AsyncSession):
        self.repository = AuditRepository(session)
        
    async def log_event(self, log: AuditLog):
        # Delegate to repository
        await self.repository.log_event(log)
        # Assuming you have a centralized Unit of Work or middleware, 
        # or commit explicitly here:
        # await self.repository.session.commit()
```

**Wiring it up**: 
During startup (e.g., in a FastAPI Dependency or your IoC container config), instantiate `PostgresAuditService` instead of the old file-logger adapter and inject it wherever an `IAuditModule` is required.

## 5. Docker Compose Snippet

```yaml
version: '3.8'

services:
  postgres:
    image: postgres:15-alpine
    container_name: sentinel-postgres
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgrespassword
      POSTGRES_DB: sentinel
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

volumes:
  postgres_data:
```
